{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "nteract": {
      "version": "0.21.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDJYgMhRRI51",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - LSTMSs\n",
        "\n",
        "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "outputId": "1f86f880-20af-4529-c036-741db9998948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "548ae1ec-474d-441d-eab0-2c504aa3c181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kohfTWBfb3pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNKNOWN>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# Perform reverse word lookup and make it callable\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2uDKWT3b-ds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "cbfbd9c3-f6f8-4d04-e8cb-b04d6aa89bcd"
      },
      "source": [
        "# Do not change this line. You need the +1 for some reason. \n",
        "max_features = len(word_index.values()) + 1\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "class_names = ['']\n",
        "\n",
        "all_articles = np.concatenate((X_train, X_test), axis=0)\n",
        "\n",
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum article length: {}\".format(len(max((all_articles), key=len))))\n",
        "print(\"Minimum article length: {}\".format(len(min((all_articles), key=len))))\n",
        "result = [len(x) for x in all_articles]\n",
        "print(\"Mean article length: {}\".format(np.mean(result)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Machine Readable Article\")\n",
        "print(\"  Article Text: \" + str(X_train[10]))\n",
        "print(\"  Article Class: \" + str(y_train[10]))\n",
        "\n",
        "# Print a review and it's class in human readable format. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Human Readable Article\")\n",
        "print(\"  Article Text: \" + decode_review(X_train[10]))\n",
        "print(\"  Article Class: \" + str(y_train[10]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum article length: 2376\n",
            "Minimum article length: 2\n",
            "Mean article length: 145.96419665122906\n",
            "\n",
            "Machine Readable Article\n",
            "  Article Text: [1, 4, 1456, 5, 141, 357, 1103, 332, 21, 4, 8239, 5, 678, 40, 10706, 218, 21, 4, 4537, 3309, 357, 76, 7, 4, 585, 121, 66, 199, 8, 144, 34, 210, 13704, 1221, 13, 1091, 1875, 50, 34, 958, 1646, 622, 77, 8, 787, 24, 858, 1580, 9545, 62, 129, 1104, 554, 77, 8, 77, 133, 569, 9, 1856, 6, 500, 198, 2424, 13, 91, 950, 225, 121, 290, 4, 195, 5, 4, 1056, 357, 869, 5787, 2943, 8, 331, 36, 64, 45, 836, 830, 185, 25, 2424, 41, 4085, 17, 12]\n",
            "  Article Class: 9\n",
            "\n",
            "Human Readable Article\n",
            "  Article Text: <START> the failure of international coffee organization talks on the reintroduction of quotas has paralysed business on the hamburg green coffee market in the past week trade sources said there was only sporadic activity for spot material which was mainly requirement buying they said adding that pre registered coffees were no longer available they said they expected brazil and colombia to open export registrations for may shipment next week however the president of the brazilian coffee institute jorio dauster said yesterday he had not yet decided when its registrations would reopen reuter 3\n",
            "  Article Class: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDCSLyAbcCY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad the articles to make them equal length\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "maxlen=225\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE7fr9dwcHaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One hotting our y values\n",
        "\n",
        "y_train = tf.one_hot(y_train, depth=46, axis=-1)\n",
        "y_test = tf.one_hot(y_test, depth=46, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlQMCX8YcHzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create our modle and compile\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, LSTM\n",
        "\n",
        "lstm = Sequential()\n",
        "lstm.add(Embedding(max_features +1, 128))\n",
        "lstm.add(LSTM(32))\n",
        "lstm.add(Dropout(0.25))\n",
        "lstm.add(Dense(46, activation='softmax'))\n",
        "\n",
        "lstm.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AKNup5ycM_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ff5e2b95-e408-4a9d-e317-962a428b15e9"
      },
      "source": [
        "# A useful tool is to look at the summary\n",
        "\n",
        "lstm.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         3966080   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                20608     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 46)                1518      \n",
            "=================================================================\n",
            "Total params: 3,988,206\n",
            "Trainable params: 3,988,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD8_2XNLcSj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "04ecd3ce-bf1e-4ec3-c3ce-8d223d3ad0cb"
      },
      "source": [
        "# 5 Epochs should show some improvement, but it takes a while!\n",
        "\n",
        "lstm_history = lstm.fit(X_train,\n",
        "                        y_train,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=5,\n",
        "                        verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "281/281 [==============================] - 14s 50ms/step - loss: 2.3492 - accuracy: 0.4211 - val_loss: 1.7868 - val_accuracy: 0.5027\n",
            "Epoch 2/5\n",
            "281/281 [==============================] - 14s 49ms/step - loss: 1.7931 - accuracy: 0.5227 - val_loss: 1.6836 - val_accuracy: 0.5450\n",
            "Epoch 3/5\n",
            "281/281 [==============================] - 13s 47ms/step - loss: 1.6068 - accuracy: 0.5764 - val_loss: 1.5969 - val_accuracy: 0.5873\n",
            "Epoch 4/5\n",
            "281/281 [==============================] - 13s 47ms/step - loss: 1.4390 - accuracy: 0.6136 - val_loss: 1.5976 - val_accuracy: 0.5703\n",
            "Epoch 5/5\n",
            "281/281 [==============================] - 13s 47ms/step - loss: 1.2639 - accuracy: 0.6639 - val_loss: 1.4827 - val_accuracy: 0.6385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC6D3KhmcUcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "18ac4a17-e9a0-47c0-fbd2-757f42ba3e98"
      },
      "source": [
        "# Let's plot it! \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lstm_history.history['loss'])\n",
        "plt.plot(lstm_history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "kGkJ8BNhRI6A",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "#####Pad_sequences is a method from Keras Preprocessing that is used to ensure all sequences in a dataset will be the same length. This is done to keep it consistent for proper calculations. \n",
        "\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "##### RNNs have \"short-term memory\". LSTMs add memorgy gates in order to use earlier weights. \n",
        "\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
        "##### Three cases for LSTMs are Robot control, grammar learning, and time series prediction. These are all cases that do well with LSTMs since there won't be an issue with shirt term memory loss. More data can be input for better predictions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and [ResNet50v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2) (pre-trained) to detect which of the images with the `frog_images` subdirectory has a frog in it. Note: You will need to upload the images to Colab. \n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GauKNxC3fLw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9e22a4f5-cd8d-417d-9ef7-861654373ca8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_TdTeX6RZhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f0867af0-1de1-46de-892a-0f384f14ed14"
      },
      "source": [
        "# I am having some serious issues getting any images to load\n",
        "\n",
        "'''from skimage.io import imread_collection\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "images = imread_collection('./frog_images/*.jpg')'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from skimage.io import imread_collection\\nfrom skimage.transform import resize\\nimport numpy as np\\n\\nimages = imread_collection('./frog_images/*.jpg')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QniSfajgRI6B",
        "colab_type": "text"
      },
      "source": [
        "The skimage function below will help you read in all the frog images into memory at once. You should use the preprocessing functions that come with ResnetV2 to help resize the images prior to inference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TehPjXFc6r1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "0c0bbb98-13cc-444e-801c-5f6c52f7aa76"
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_images_download\n",
            "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14550 sha256=f451d890a3eeaeb62fe278675795ca52082ff5879d9c38285142020423af54de\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
            "Successfully built google-images-download\n",
            "Installing collected packages: selenium, google-images-download\n",
            "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKbCa7_emgQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "eb927b71-4642-4ec7-9caf-28b55c7be177"
      },
      "source": [
        "# Hopefully this works \n",
        "\n",
        "from google_images_download import google_images_download\n",
        "\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"frog\", \"limit\": 5, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = frog\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "\n",
            "\n",
            "Unfortunately all 5 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
            "\n",
            "Errors: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72IgUOC0mgXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "Your goal is to validly run ResNet50v2 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
        "\n",
        "*Hint* - ResNet 50v2 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goals:* \n",
        "- Check for other things such as fish.\n",
        "- Print out the image with its predicted label\n",
        "- Wrap everything nicely in well documented fucntions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "def process_img_path(img_path):\n",
        "    return image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "def img_contains_frog(img):\n",
        "    \"\"\" Scans image for Frogs\n",
        "    \n",
        "    Should return a boolean (True/False) if a frog is in the image.\n",
        "    \n",
        "    Inputs:\n",
        "    ---------\n",
        "    img:  Precrossed image ready for prediction. The `process_img_path`             function should already be applied to the image. \n",
        "    \n",
        "    Returns: \n",
        "    ---------\n",
        "    frogs (boolean):  TRUE or FALSE - There are frogs in the image.\n",
        "    \n",
        "    \"\"\"\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    model = ResNet50V2(weights='imagenet')\n",
        "    features = model.predict(x)\n",
        "    results = decode_predictions(features)[0]\n",
        "    print(results)\n",
        "    if 'frog' in results[0][1] and results[0][2] > 0.25:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mmJ896Fm-bR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "4a225c19-88ca-4b98-8cf3-4faf98d2a941"
      },
      "source": [
        "# Not one says frog here :/ \n",
        "\n",
        "imagelist = glob.glob('/content/drive/My Drive/frog_images2/*.jpg')\n",
        "for x in imagelist:\n",
        "    print(img_contains_frog(process_img_path(x)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('n02089973', 'English_foxhound', 1.0), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0), ('n02391049', 'zebra', 0.0)]\n",
            "False\n",
            "[('n02089973', 'English_foxhound', 1.0), ('n07613480', 'trifle', 2.155502e-24), ('n15075141', 'toilet_tissue', 0.0), ('n02317335', 'starfish', 0.0), ('n02389026', 'sorrel', 0.0)]\n",
            "False\n",
            "[('n02356798', 'fox_squirrel', 0.99999774), ('n02089973', 'English_foxhound', 2.2708334e-06), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0)]\n",
            "False\n",
            "[('n02089973', 'English_foxhound', 0.99999964), ('n02356798', 'fox_squirrel', 3.5420362e-07), ('n02085782', 'Japanese_spaniel', 3.6510233e-26), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0)]\n",
            "False\n",
            "[('n07613480', 'trifle', 1.0), ('n02089973', 'English_foxhound', 3.598205e-12), ('n02356798', 'fox_squirrel', 8.3724164e-38), ('n15075141', 'toilet_tissue', 0.0), ('n02317335', 'starfish', 0.0)]\n",
            "False\n",
            "[('n02356798', 'fox_squirrel', 0.99808156), ('n02089973', 'English_foxhound', 0.0019184191), ('n02085782', 'Japanese_spaniel', 2.2365232e-15), ('n01688243', 'frilled_lizard', 5.6837007e-34), ('n02795169', 'barrel', 6.158709e-35)]\n",
            "False\n",
            "[('n02356798', 'fox_squirrel', 0.9999999), ('n02089973', 'English_foxhound', 1.767134e-07), ('n07613480', 'trifle', 1.3978511e-11), ('n02085782', 'Japanese_spaniel', 2.747753e-31), ('n15075141', 'toilet_tissue', 0.0)]\n",
            "False\n",
            "[('n02356798', 'fox_squirrel', 1.0), ('n15075141', 'toilet_tissue', 0.0), ('n02319095', 'sea_urchin', 0.0), ('n02395406', 'hog', 0.0), ('n02391049', 'zebra', 0.0)]\n",
            "False\n",
            "[('n02089973', 'English_foxhound', 1.0), ('n02356798', 'fox_squirrel', 4.3705335e-28), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0)]\n",
            "False\n",
            "[('n02749479', 'assault_rifle', 0.9999633), ('n07615774', 'ice_lolly', 3.669514e-05), ('n02085782', 'Japanese_spaniel', 8.2832347e-13), ('n02089973', 'English_foxhound', 1.713717e-20), ('n03630383', 'lab_coat', 1.8543765e-28)]\n",
            "False\n",
            "[('n02356798', 'fox_squirrel', 0.99409676), ('n02089973', 'English_foxhound', 0.0059031835), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0)]\n",
            "False\n",
            "[('n02089973', 'English_foxhound', 1.0), ('n02356798', 'fox_squirrel', 1.6864187e-35), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0)]\n",
            "False\n",
            "[('n07615774', 'ice_lolly', 1.0), ('n02089973', 'English_foxhound', 1.1343464e-15), ('n15075141', 'toilet_tissue', 0.0), ('n02317335', 'starfish', 0.0), ('n02389026', 'sorrel', 0.0)]\n",
            "False\n",
            "[('n02356798', 'fox_squirrel', 1.0), ('n02089973', 'English_foxhound', 5.7327737e-32), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0)]\n",
            "False\n",
            "[('n02089973', 'English_foxhound', 1.0), ('n02356798', 'fox_squirrel', 9.820271e-26), ('n15075141', 'toilet_tissue', 0.0), ('n02321529', 'sea_cucumber', 0.0), ('n02395406', 'hog', 0.0)]\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__ \n",
        "\n",
        "#####Autoencoders can be used for denoising images, to make the images smoother, or to enhance a certain part of the image beyond what has previously been capable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "- What are the threats posed by AI to our society?\n",
        "- How do you think we can counteract those threats? \n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows.\n",
        "\n",
        "#####- I consider Linear Algebra and Applied Modeling my strongest suit. \n",
        "\n",
        "#####- I would love to dive into Neural Networks some more. We touch on base items, and it's all just overview. But I know it's hard to fit everything into a schedule.\n",
        "\n",
        "##### - Data Science will be strong and steady in 5 years. There will be high demand for data scientists!\n",
        "\n",
        "##### - Well, any human interaction can soil AI. We are imperfect, and machines are 1s and 0s. We can be seen as a 0 and irridicated. \n",
        "\n",
        "##### - We can establish an AI that will help seek out \"unlawful\" or \"unethical\" AI systems. Someone would need to keep that in check as well though.\n",
        "\n",
        "##### - I do! We just need the processing power for it :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMM0bJnzRI6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "5a10b7cb-3ad9-4a87-e59b-f5de4546fe64"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}