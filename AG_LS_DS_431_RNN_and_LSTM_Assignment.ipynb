{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "AG LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ash827/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/AG_LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnHtqL1wj4Q1",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA5rnzv-rboX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "71ef1c9a-675e-4eb8-c531-21d43dbf5099"
      },
      "source": [
        "# Check that we have a GPU instance of Colab\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 23 02:32:02 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "# Import the libraries\n",
        "\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj5hSJYtv5ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "23b9d521-120c-49a2-ad74-1f809e7c9f3e"
      },
      "source": [
        "path = get_file(\n",
        "    '100-0.txt',\n",
        "    origin='https://www.gutenberg.org/files/100/100-0.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
            "5783552/5777367 [==============================] - 2s 0us/step\n",
            "corpus length: 5573152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIKCUV-v5lH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3108df25-a465-400a-ff65-18a019721743"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjycLf-mv5nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca9ca9e1-65ec-410f-b162-5e37246fb3f7"
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 1857704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89LlPJBH4fww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3953592d-3f22-47e4-ea4c-1527f8a0c195"
      },
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGl7HLC64fy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d43913ca-ea89-485d-a101-5edfc55838bb"
      },
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBJyiKql4f1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K99FWYnev5p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFd0UAGvv5sa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1375f802-d766-4ea0-e2e8-7da8b151ca55"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1857704/1857704 [==============================] - 1178s 634us/step - loss: 1.6347\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"edward. go, trumpet, to the walls, and s\"\n",
            "edward. go, trumpet, to the walls, and some the street the content.\n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                   \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"edward. go, trumpet, to the walls, and s\"\n",
            "edward. go, trumpet, to the walls, and sirral,\n",
            "    and your horses of my life of the truath,\n",
            "    and the street comfort, and as i care thee the say thee an athen.\n",
            "                                                                                                                                                                                                                                                                                     \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"edward. go, trumpet, to the walls, and s\"\n",
            "edward. go, trumpet, to the walls, and some strivings' lains.\n",
            "  juliet. o first by which as the make it\n",
            "that wallies of your love, ever eashens,\n",
            "and nor dost, yet turn a gill set of bear'st\n",
            "neege talk, i have hin a talls drung; and, now care all the little knight.\n",
            "  gloucester. androrns king, much enimed their offerfave.\n",
            "  pass. tellrim him, every ands a fearves, unctor double an saus!\n",
            "  thousandin. cleepheri.\n",
            "\n",
            "\n",
            "        enter aarfudly t\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"edward. go, trumpet, to the walls, and s\"\n",
            "edward. go, trumpet, to the walls, and sht\n",
            "    somessation this nighs it all iuthinine\n",
            "    enten give. we course and en'lust art leturatrs, and\n",
            "    a witch too lord difir’d his norriagel; pando.\n",
            "  king. seborsage, let heservacy to\n",
            "  saw pawn, lookleh, anylam, wanten rast is\n",
            "beatee\n",
            "\n",
            "  v. ayon. twasioned, hane?\n",
            "\n",
            "  air, colplacaleting of her, orlangd, hastie on.\n",
            " walqu and at me., my ahord'd.\n",
            "  groants. allow, noliefrateles'd?\n",
            "\n",
            "their goodl\n",
            "Epoch 2/5\n",
            "1857704/1857704 [==============================] - 1169s 630us/step - loss: 1.5176\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"  [alarum. here another skirmish]\n",
            "    it\"\n",
            "  [alarum. here another skirmish]\n",
            "    it is the state and the send the hearts,\n",
            "    i have the stread for the man to an enter\n",
            "    the true and her to the hearts the true.\n",
            "    the man it see the strenger of the strip to the soul honest for the house.\n",
            "    the strenger to the seas and strenghes.\n",
            "    the state to him to shall see the servant.\n",
            "    the sun of the state and her hearts him\n",
            "    when the shall i would see the wife of the consembre\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"  [alarum. here another skirmish]\n",
            "    it\"\n",
            "  [alarum. here another skirmish]\n",
            "    it is gratient with of his dear for a party\n",
            "    the life a attending of the seen too,\n",
            "    i have say his wife to me need for the greatness,\n",
            "    bear the answer here your single warring to me not but the mouth\n",
            "    the best for a most stange of his sun\n",
            "    shalt the my counterfects be the courty and faver to all a true.\n",
            "  claudio. what she shall not "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the great the trantain\n",
            "    the benedick  shall be th\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"  [alarum. here another skirmish]\n",
            "    it\"\n",
            "  [alarum. here another skirmish]\n",
            "    it be will not notest; or my malicte ophela\n",
            "    ite odd shall. die aor master!\n",
            "\n",
            "scene i. enter attendance. i’ll seat be poek shall o, my doest be me,\n",
            "    do be hath honour will\n",
            "to might tell relm with crections of mird.\n",
            "\n",
            "ally,\n",
            "    must by young man. is connow here down out at the receive,\n",
            "did john on very hearty.\n",
            "\n",
            "botius.\n",
            "much, taking, your mothe seal'st thrue.\n",
            "    bag what we be fears, for our proy\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"  [alarum. here another skirmish]\n",
            "    it\"\n",
            "  [alarum. here another skirmish]\n",
            "    it shall cont ofes dissape, what make our rest, ar\n",
            "    dost that no, cirtia gobsts.\n",
            "\n",
            "and such good all.\n",
            "  second counterbut. king the tower lerruik my sown, of king fioity,\n",
            "    the maganal\n",
            "preference, loved nad'd offul.\n",
            "       enter here with not,\n",
            "shepitur be one ofn friends shift by dempes.\n",
            "\n",
            "kungerne.\n",
            "you have emblach the adritging.\n",
            "  tituen. no way vincenseberfolk,\n",
            "    would so thy, envero’s life \n",
            "Epoch 3/5\n",
            "1857704/1857704 [==============================] - 1157s 623us/step - loss: 1.4920\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"s brow-bound with the oak. his pupil age\"\n",
            "s brow-bound with the oak. his pupil age the constant the such and the strangland of the part of the constant the speech the sake the strange,\n",
            "    the strange the father with me the part and and the strange,\n",
            "    and the speech the shame and the suffolk.\n",
            "    i have fall the coming the constant her father.\n",
            "                                                                                                                                      \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"s brow-bound with the oak. his pupil age\"\n",
            "s brow-bound with the oak. his pupil age,\n",
            "                                                                                                                                                                                                                                                                                                                                               exeunt\n",
            "                                                        \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"s brow-bound with the oak. his pupil age\"\n",
            "s brow-bound with the oak. his pupil age, you stumats another peace see.\n",
            "\n",
            "nay-seas.\n",
            "and of, goddes the body, your prevcife\n",
            "    :  nory it in salcors'lord furse.\n",
            "  corius. commend you meannort, from time, emilia, pistol, hear, senatol;\n",
            "    ere not commend, now yibeds more; my ungoil eyes,\n",
            "plae we shall the wills the fat it match suks it uppise\n",
            "    lool-unperwy my counterfeit fro’thened;\n",
            "too gress send it is.\n",
            "\n",
            "first , i let me lew’d ar, t\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"s brow-bound with the oak. his pupil age\"\n",
            "s brow-bound with the oak. his pupil age her. we have specias sorn true.\n",
            "    tnokes you fire twif parero me!\n",
            "now posskright whanking cheek’d.\n",
            "  with cursionus; do indee, and dection mouth;\n",
            "providee the brace. see tamy froblcisteret_bheke!\n",
            "  sleep.\n",
            "\n",
            "earrace, lord,  enead is not pling sin the how.\n",
            "  mrs. by open. enoband of her iund,\n",
            "sfarc!\n",
            "  kno scarming tenedis a forse\n",
            "to arm avrifier: why.\n",
            "\n",
            "?\n",
            "\n",
            "iachimo.\n",
            "my lord, and ’’! a.\n",
            "  \n",
            "\n",
            "scene i. \n",
            "Epoch 4/5\n",
            "1857704/1857704 [==============================] - 1149s 619us/step - loss: 1.4815\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" palace\n",
            "\n",
            "enter trumpets, sounding; then \"\n",
            " palace\n",
            "\n",
            "enter trumpets, sounding; then the prove the cares of the wise and strange.\n",
            "                                                                                                                                                                                                                                                                                                                                                                   \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" palace\n",
            "\n",
            "enter trumpets, sounding; then \"\n",
            " palace\n",
            "\n",
            "enter trumpets, sounding; then a sanness and sint.\n",
            "\n",
            "soldien.\n",
            "i see your more sen the part of your father,\n",
            "    is the sature things in a captain life,\n",
            "    and have some things men and not in the engest is thee words.\n",
            "    and go to the chamber. the caesar with the life.\n",
            "                                                                                                                                                                  \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" palace\n",
            "\n",
            "enter trumpets, sounding; then \"\n",
            " palace\n",
            "\n",
            "enter trumpets, sounding; then thou the wordsted; and very heaven,\n",
            "i speak store that adorall two fair thing.\n",
            "that you know i is an way that i derote me.\n",
            "    assur'd into this pursfge thats have longer profait.\n",
            "    for long thee in the courd my lostion lies to return and must silts\n",
            "    what to to be foble, you shall usech is\n",
            "the very.                                                                                    eekn stands\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" palace\n",
            "\n",
            "enter trumpets, sounding; then \"\n",
            " palace\n",
            "\n",
            "enter trumpets, sounding; then vanca nog fance,\n",
            "    i go desing you despergu and blost,\n",
            "lenius’s thee, lest me; but i know him, yout yead?\n",
            "\n",
            "or’t hither vaigh, or baube. if you ear those on; and upon thy words.\n",
            "i have greene fastemonast collon that have them me’s sweet.\n",
            "why love’s \n",
            "  pevcall food. forget’st good in a mackbine.\n",
            "\n",
            " [here,\n",
            "she is lord. ha'll come that brother a unthese prepure of ecribsed,\n",
            "did not at his key forest\n",
            "\n",
            "Epoch 5/5\n",
            "1857704/1857704 [==============================] - 1142s 615us/step - loss: 1.5344\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"considered. that’s villanous, and shows \"\n",
            "considered. that’s villanous, and shows the common the most the dead.\n",
            "   a [t on the hange the common the constan and maste\n",
            "          (        tebatcy masse that the part the common the common the fathers and and the maste\n",
            "            ) now i am a common the part the world and maste the sonded the commont the poor daught her maste\n",
            "            (anon and to make the dead the fathers is she my the construme so like her inde,\n",
            " andyind. what\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"considered. that’s villanous, and shows \"\n",
            "considered. that’s villanous, and shows and thy late.\n",
            "   a [te[venk, what lord the since the thine,\n",
            "     hhr nfvise will see the root thee\n",
            "    and o—of lawnible and a danger that command him in you have dear the conspecy.\n",
            " enger and so if you will proted it west the days that wear and dead. and deliver, you harl that i would him didach'd\n",
            "     haerite that her love, and the commone and face make mead periment\n",
            "                            \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"considered. that’s villanous, and shows \"\n",
            "considered. that’s villanous, and shows the cover that but he weary sege,\n",
            " i thiv[_uce. rich it wish.my, me i seek’d you terrage conscie the ’the fire the pitsding of treast obliri much, hor?\n",
            "wilke thoughards on her gonoun, alivs they portens and behald cupinic heer the boocline.ached in\n",
            "     t that ellow’st commands him fork, no apmitise\n",
            "in otheld and suffy, but thy genery,\n",
            "   ot an my hefry, morr. why seed an look ane?\n",
            "but i will no w\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"considered. that’s villanous, and shows \"\n",
            "considered. that’s villanous, and shows do from\n",
            "                      as” cyposseo, sir, thir, hashes king. her countess.\n",
            "   ot n \n",
            "fill octasicio. i wouth kashesoft to freft uil\n",
            "\n",
            " lent of myst ackings on him on his did jeli\n",
            "rake, we, prodesrpid\n",
            "con?\n",
            "\n",
            "vauces.\n",
            "yamese!cman’s most madune, a loves. what pergeined\n",
            "susam. worth i will's the word thou and thir not founce\n",
            "ypeids. i sham puch ont.mife enough mord. you have juthers enow pacgod,\n",
            "th\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd41138a0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pyGmfAi-Iwh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}